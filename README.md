# Autogen AI Agent: Todo Information Retriever

This project implements an AI agent system using the Autogen framework and the Mistral `open-mistral-nemo` Large Language Model (LLM). The agent is designed to retrieve details (title and completion status) for a specific "todo" item by its ID from the public JSONPlaceholder API.

This project was developed as part of the Machine Learning course exam (Spring 2025).

## Features

*   **Tool Usage:** The agent utilizes a custom Python tool (`get_todo_data`) to fetch data from an external API (JSONPlaceholder).
*   **Code Generation & Execution:** The LLM (via the `TodoAssistant` agent) generates Python code to parse the JSON response from the API. This code is then executed by the `UserProxyAgent`.
*   **Multi-Agent Interaction:** Demonstrates a basic two-agent setup (`UserProxyAgent` and `TodoAssistant`) collaborating to solve the task.
*   **Error Handling:** The tool and agent system include basic error handling for invalid inputs or API issues.

## Project Structure
.
├── app.py # Main application script to run the Autogen agents
├── tools.py # Contains the API calling tool (get_todo_data)
├── requirements.txt # Python dependencies
├── .env.example # Example environment file (DO NOT commit your actual .env file)
├── README.md # This file
├── project_description.pdf # (Or .md) Detailed project synopsis/document (1-3 pages)
├── use_cases.md # Examples of inputs and desired outputs
└── coding/ # Directory created by Autogen for storing/executing generated code (add to .gitignore)


## Dependencies

*   Python 3.9+
*   **Autogen Framework:** This project uses a specific version/fork of Autogen suitable for Mistral API integration (as used in prior course assignments):
    *   `autogen-agentchat @ git+https://github.com/patrickstolc/autogen.git@0.2#egg=autogen-agentchat`
*   **Mistral AI Client:** `mistralai==1.2.3`
*   **Other Core Libraries:**
    *   `python-dotenv` (for managing API keys)
    *   `requests` (for making HTTP requests in the tool)
    *   (Include `ollama` and `fix-busted-json` if they were part of the required stack for the Mistral setup, even if not directly used by this specific agent's logic, to match the previous assignment's environment).

A full list of Python package dependencies is provided in `requirements.txt`.

## Setup Instructions

1.  **Clone the Repository:**
    ```bash
    git clone [URL_OF_YOUR_GITHUB_REPOSITORY]
    cd [YOUR_REPOSITORY_NAME]
    ```

2.  **Create and Activate a Python Virtual Environment:**
    (Recommended)
    ```bash
    python -m venv venv
    # On Windows
    # venv\Scripts\activate
    # On macOS/Linux
    # source venv/bin/activate
    ```

3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *Note: If you encounter issues installing `autogen-agentchat` directly via pip due to git dependencies, you might need to ensure git is installed and in your PATH, or consult any specific instructions provided for that package in your course.*

4.  **Set Up Environment Variables:**
    Create a `.env` file in the root of the project directory by copying `.env.example`:
    ```bash
    cp .env.example .env
    ```
    Open the `.env` file and add your Mistral API key:
    ```
    MISTRAL_API_KEY="your_actual_mistral_api_key_here"
    ```
    **Important:** Do NOT commit your actual `.env` file to version control. The `.gitignore` file should prevent this.

## How to Run the Code

1.  Ensure your virtual environment is activated and all dependencies are installed.
2.  Make sure your `MISTRAL_API_KEY` is correctly set in the `.env` file.

3.  Execute the main application script:
    ```bash
    python app.py
    ```

4.  The script will initiate a conversation between the agents. The default task is to fetch details for "todo item number 5". You can observe the agent interaction, tool usage, and code execution in the terminal output.

5.  **To Test Different Inputs:**
    Modify the `user_initial_message` variable within the `app.py` script. For example:
    ```python
    # In app.py, find this line:
    # user_initial_message = "Can you get me the details for todo item number 5?"
    
    # Change it to test other scenarios:
    # user_initial_message = "What about todo number 1?"
    # user_initial_message = "Fetch details for todo 0" # Test invalid input error
    # user_initial_message = "I need info on todo 999888" # Test API 404 error
    ```
    Then, re-run `python app.py`.

## Agent Design Overview

The system consists of two main Autogen agents:

1.  **`UserProxyAgent` ("UserProxy"):**
    *   Initiates the chat with the user's request.
    *   Executes tools (like `get_todo_data`) when requested by the `TodoAssistant`.
    *   Executes Python code generated by the `TodoAssistant` for tasks like JSON parsing.
    *   Does not require human input (`human_input_mode="NEVER"`).

2.  **`AssistantAgent` ("TodoAssistant"):**
    *   Powered by the Mistral `open-mistral-nemo` LLM.
    *   Receives user requests and tool outputs.
    *   Reasons about the task and decides when to use the `get_todo_data` tool.
    *   Generates Python code to parse the JSON data returned by the tool.
    *   Formulates the final response to the user.
    *   Guided by a detailed system message outlining its workflow, tool usage, code generation strategy, and error handling.

The LLM configuration for the `TodoAssistant` uses `native_tool_calls: False` and defines the available tools using a schema passed to the `tools` parameter, compatible with the Autogen fork used.

*(You can briefly mention the ReAct-like flow if you discuss it in your main document).*